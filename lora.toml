[Model]
#模型加载路径，填写clip_model、text_encoder、transformer、vae、model_index.json所在的文件夹路径
base_model_path = "/root/autodl-tmp/NewBie"
# vae是否使用"reflect"的padding模式，适用于在该参数下训练的vae
vae_reflect_padding = true

# 是否信任远程代码（Gemma 和 CLIP 模型需要）
trust_remote_code = true

# 训练输出目录
output_dir = "/root/autodl-tmp/output"

# 输出的 LoRA 模型名称（最终保存为 output_dir/output_name/）
output_name = "NewBieLoRA"

# 是否加载预训练的 LoRA 文件（绝对路径）
resume_from_lora = "/root/autodl-tmp/output/NewBieLoRA"

# 是否启用 EMA (指数移动平均)
use_ema = true

# EMA 衰减率 (推荐 0.999 或 0.9999)
ema_decay = 0.999

# =============================================================================
# 数据配置
# =============================================================================
# 训练数据目录
# 支持 kohya_ss 风格：目录名格式为 "重复次数_描述"
# 例如：data/train/10_character/ 表示该目录下的图像重复10次
# 每张图像需要有对应的 .txt 文件作为文本描述
train_data_dir = "/root/autodl-tmp/datasets"

# 训练图像分辨率
resolution = 1024
# 图像分箱参数
min_bucket_reso = 512
max_bucket_reso = 2048
bucket_reso_step = 64
# 是否打乱tag
shuffle_caption = true
keep_tokens_separator = "|||"
# 是否基于"<split>"分割符分割caption后，随机选取分隔后部分作为caption，用于NLP和Tags的混合训练
enable_wildcard = true
# "空"caption的概率，开启利于CFG
caption_dropout_rate = 0.1
# 随机丢弃tag的概率
caption_tag_dropout_rate = 0
# 随机丢弃artist标签的概率
drop_artist_rate = 0.2

# 是否启用多分辨率损失 (Multi-Resolution Loss)
# true: 在原始分辨率和下采样后的分辨率上同时计算 Loss，有助于学习全局结构
# false: 仅在原始分辨率计算 Loss，节省显存和计算量
use_multires_loss = true

# 多分辨率下采样的倍率
multires_factor = 4

# DataLoader 工作线程数
dataloader_num_workers = 8

# 启用分辨率分桶（Resolution Bucketing）
# true: 支持多种宽高比（1:1, 3:4, 4:3, 9:16, 16:9）
# false: 所有图像都调整为正方形（resolution × resolution）
enable_bucket = true

# 启用数据缓存（推荐）
# true: 预先缓存 VAE latents, 加速训练并节省显存
# false: 每次实时编码（慢，但不占用磁盘空间）
# 缓存文件保存在数据集同目录：图片.safetensors,
use_cache = false

# Gemma3 系统提示词（仅用于 Gemma3，不影响 Jina CLIP）
gemma3_prompt = "You are an assistant designed to generate high-quality anime images with the highest degree of image-text alignment based on textual prompts. <Prompt Start>\n"

# wandb的api key, 用于查看训练损失与过程 
wandb_key = ""

# =============================================================================
# 训练超参数
# =============================================================================
# 批次大小（每次前向传播处理的图像数量）
train_batch_size = 1

# 训练轮数（遍历整个数据集的次数）
num_epochs = 10

# Checkpoint 保存间隔（按 Epoch）
# 每隔多少个 epoch 保存一次检查点
# 设置为 0 表示每个 epoch 都保存（默认）
save_epochs_interval = 1

# 学习率
#默认推荐推荐1e-4和2e-4，可自行测试
learning_rate = 2e-4

# 学习率调度器（控制学习率在训练过程中的变化）
# 可选值：
#   - "constant": 恒定学习率，不变化
#   - "cosine": 余弦退火，推荐，平滑下降
#   - "linear": 线性衰减
#   - "cosine_with_restarts": 带重启的余弦，用于长时间训练
lr_scheduler = "cosine"

# 学习率预热步数
lr_warmup_steps = 1000

# 梯度检查点
gradient_checkpointing = false
# 梯度累积
gradient_accumulation_steps = 32

# 混合精度训练
# 可选值：
#   - "no": 不使用混合精度（fp32），精度最高但显存占用最大
#   - "fp16": Float16，兼容性好，适用于所有 GPU
#   - "bf16": BFloat16，推荐，适用于 Ampere 及更新 GPU（RTX 30/40 系列，A100，H100）
# 推荐：bf16（如果 GPU 支持）
mixed_precision = "bf16"

# =============================================================================
# LoRA 配置
# =============================================================================
# LoRA rank（秩）
lora_rank = 96

# LoRA alpha
# 使用rslora时建议固定
lora_alpha = 16

# LoRA dropout
# 推荐0.05-0.1或0
lora_dropout = 0.0

# 是否训练标准层 TODO
train_norm = true

# 是否启用DoRA，启用时建议关闭lora_dropout提升性能，不支持olora和pissa初始化
use_dora = true

# 是否启用rsLoRA
# 修改LoRA缩放为lora_alpha / r -> lora_alpha / math.sqrt(r)
# 本质是解耦了 学习率 与 lora_rank 间的关系
# △W (LoRA)的标准差与sqrt(r)成正比，因此必须根据r进行缩放，类似Kaiming初始化
# 启用时如果使用使用comfyui进行推理，必须使用正确的strength，计算公式 strength = lora_alpha / sqrt(lora_rank)
use_rslora = true

# =============================================================================
# LoRA 目标模块配置
# =============================================================================
lora_target_modules = [
    "attention.qkv",           
    "attention.out",
    "feed_forward.w1",
    "feed_forward.w2",
    "feed_forward.w3",
    "adaLN_modulation.1",
    "cap_embedder.1",
    "t_embedder.mlp.0",
    "t_embedder.mlp.2",
    "time_text_embed.1",
    "clip_text_pooled_proj.1", 
]
# =============================================================================
# 优化器配置
# =============================================================================
[Optimization]

# 优化器类型
# 可选值：
#   - "AdamW": 标准 AdamW 优化器
#   - "AdamW8bit": 8-bit AdamW 优化器（推荐）
optimizer_type = "AdamW8bit"
weight_decay = 0.001

# 梯度裁剪范数（Gradient Clipping）
# 推荐值：0.5 - 2.0
gradient_clip_norm = 1.0

# FlashAttention-2 优化
use_flash_attention_2 = true










